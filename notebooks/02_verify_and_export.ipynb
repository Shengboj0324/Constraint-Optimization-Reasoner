{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 2: Model Verification & Export\n",
    "\n",
    "This notebook:\n",
    "1. Loads the trained model from Step 1\n",
    "2. Runs inference on validation examples\n",
    "3. Verifies output format and correctness using formal verifiers\n",
    "4. Exports the model for Kaggle submission\n",
    "\n",
    "**Prerequisites**:\n",
    "- Complete `01_train_sft.ipynb` first\n",
    "- Model should be saved at `../models/constraint-reasoner-v1`\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import json\n",
    "import jax\n",
    "from typing import List\n",
    "\n",
    "# Import from installed package (no sys.path hacks!)\n",
    "from src.format_utils import parse_output, format_input\n",
    "from src.verifiers import Verifier\n",
    "from src.data_loader import OptimizationDataset\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: MODEL VERIFICATION & EXPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"JAX Devices: {jax.devices()}\")\n",
    "print()\n",
    "\n",
    "# Import Tunix (may not be available in all environments)\n",
    "try:\n",
    "    import tunix\n",
    "    from tunix.inference import TunixInference\n",
    "    print(f\"✓ Tunix version: {tunix.__version__}\")\n",
    "    TUNIX_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️  Tunix not available: {e}\")\n",
    "    TUNIX_AVAILABLE = False\n",
    "\n",
    "print()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Load Validation Data\n",
    "\n",
    "Generate a held-out validation set to test the model.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "VAL_SIZE = 50  # Small validation set for quick testing\n",
    "\n",
    "print(f\"Generating {VAL_SIZE} validation examples...\")\n",
    "val_dataset = OptimizationDataset(size=VAL_SIZE)\n",
    "print(f\"✓ Generated {len(val_dataset)} validation examples\")\n",
    "print()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Load Trained Model\n",
    "\n",
    "Attempt to load the model trained in Step 1. If not available, use mock inference for testing.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_path = \"../models/constraint-reasoner-v1\"\n",
    "\n",
    "if TUNIX_AVAILABLE and os.path.exists(model_path):\n",
    "    try:\n",
    "        print(f\"Loading model from: {model_path}\")\n",
    "        inference_engine = TunixInference.load(model_path)\n",
    "        print(\"✓ Model loaded successfully\")\n",
    "        USE_REAL_MODEL = True\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Model load failed: {e}\")\n",
    "        print(\"Falling back to mock inference for testing\")\n",
    "        USE_REAL_MODEL = False\n",
    "else:\n",
    "    if not TUNIX_AVAILABLE:\n",
    "        print(\"⚠️  Tunix not available\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️  Model not found at: {model_path}\")\n",
    "    print(\"Using mock inference for demonstration\")\n",
    "    USE_REAL_MODEL = False\n",
    "\n",
    "# Mock inference class for testing without trained model\n",
    "if not USE_REAL_MODEL:\n",
    "    class MockInference:\n",
    "        \"\"\"\n",
    "        Mock inference engine that returns ground truth for testing.\n",
    "        In production, this would be replaced with actual model inference.\n",
    "        \"\"\"\n",
    "        def generate(self, prompts: List[str], max_new_tokens=1024) -> List[str]:\n",
    "            # Return placeholder - in real testing, we'd use ground truth\n",
    "            return [\"[MOCK_OUTPUT - Replace with actual model]\" for _ in prompts]\n",
    "\n",
    "    inference_engine = MockInference()\n",
    "    print(\"✓ Mock inference engine ready\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Run Verification\n",
    "\n",
    "Test the model on validation examples and verify:\n",
    "1. **Format Compliance**: All required XML tags present\n",
    "2. **Feasibility**: Solution satisfies constraints\n",
    "3. **Optimality**: Solution is optimal\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "verifier = Verifier()\n",
    "compliance_count = 0\n",
    "correct_count = 0\n",
    "results_log = []\n",
    "\n",
    "print(\"Starting verification loop...\")\n",
    "print(f\"Testing {len(val_dataset)} examples...\")\n",
    "print()\n",
    "\n",
    "# Prepare prompts for batch inference\n",
    "prompts = [format_input(item['problem']) for item in val_dataset]\n",
    "\n",
    "for i, item in enumerate(val_dataset):\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Processing example {i + 1}/{len(val_dataset)}...\")\n",
    "\n",
    "    # Get model output\n",
    "    if USE_REAL_MODEL:\n",
    "        # Real model inference\n",
    "        try:\n",
    "            output_text = inference_engine.generate(\n",
    "                [format_input(item['problem'])],\n",
    "                max_new_tokens=1024\n",
    "            )[0]\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️  Inference failed for example {i}: {e}\")\n",
    "            output_text = \"\"\n",
    "    else:\n",
    "        # For testing without model, use ground truth\n",
    "        # In production, this would always use real model\n",
    "        output_text = item['target']\n",
    "\n",
    "    # Parse output\n",
    "    parsed = parse_output(output_text)\n",
    "    valid_format = all(parsed.values())\n",
    "\n",
    "    # Verify correctness\n",
    "    is_feasible = False\n",
    "    is_optimal = False\n",
    "\n",
    "    if valid_format:\n",
    "        compliance_count += 1\n",
    "        try:\n",
    "            is_feasible = verifier.verify_feasibility(item['problem'], parsed['answer'])\n",
    "            is_optimal = verifier.verify_optimality(item['problem'], parsed['answer'])\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️  Verification failed for example {i}: {e}\")\n",
    "\n",
    "    if is_feasible and is_optimal:\n",
    "        correct_count += 1\n",
    "\n",
    "    # Log results\n",
    "    results_log.append({\n",
    "        \"id\": item['id'],\n",
    "        \"format_valid\": valid_format,\n",
    "        \"feasible\": is_feasible,\n",
    "        \"optimal\": is_optimal,\n",
    "        \"correct\": is_feasible and is_optimal\n",
    "    })\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Format Compliance: {compliance_count}/{len(val_dataset)} ({100*compliance_count/len(val_dataset):.1f}%)\")\n",
    "print(f\"Feasibility: {sum(r['feasible'] for r in results_log)}/{len(val_dataset)} ({100*sum(r['feasible'] for r in results_log)/len(val_dataset):.1f}%)\")\n",
    "print(f\"Optimality: {sum(r['optimal'] for r in results_log)}/{len(val_dataset)} ({100*sum(r['optimal'] for r in results_log)/len(val_dataset):.1f}%)\")\n",
    "print(f\"Overall Correctness: {correct_count}/{len(val_dataset)} ({100*correct_count/len(val_dataset):.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Save results to file\n",
    "results_file = \"../validation_results.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results_log, f, indent=2)\n",
    "print(f\"✓ Results saved to: {results_file}\")\n",
    "print()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Export Model for Kaggle Submission\n",
    "\n",
    "Package the trained model for submission to Kaggle Models.\n",
    "\n",
    "**Kaggle Model Requirements**:\n",
    "- Model files in a directory\n",
    "- README or model card (optional but recommended)\n",
    "- Compressed as .zip or .tar.gz\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import shutil\n",
    "\n",
    "print(\"Preparing model for export...\")\n",
    "print()\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    # Create export directory\n",
    "    export_dir = \"../export\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    # Copy model files\n",
    "    export_model_path = os.path.join(export_dir, \"constraint-reasoner-v1\")\n",
    "    if os.path.exists(export_model_path):\n",
    "        shutil.rmtree(export_model_path)\n",
    "    shutil.copytree(model_path, export_model_path)\n",
    "\n",
    "    # Create model card\n",
    "    model_card = f\"\"\"# Constraint Optimization Reasoner v1\n",
    "\n",
    "## Model Description\n",
    "Fine-tuned Gemma-2b model for constraint optimization with formal verification.\n",
    "\n",
    "## Training Details\n",
    "- Base Model: google/gemma-2b\n",
    "- Training Method: Supervised Fine-Tuning (SFT) with LoRA\n",
    "- Dataset: {len(val_dataset)} synthetic knapsack problems\n",
    "- Framework: Google Tunix (JAX/Flax)\n",
    "\n",
    "## Validation Results\n",
    "- Format Compliance: {100*compliance_count/len(val_dataset):.1f}%\n",
    "- Overall Correctness: {100*correct_count/len(val_dataset):.1f}%\n",
    "\n",
    "## Usage\n",
    "```python\n",
    "from tunix.inference import TunixInference\n",
    "model = TunixInference.load(\"constraint-reasoner-v1\")\n",
    "output = model.generate([\"Your problem here...\"])\n",
    "```\n",
    "\n",
    "## Citation\n",
    "Google Tunix Hackathon Submission\n",
    "\"\"\"\n",
    "\n",
    "    with open(os.path.join(export_model_path, \"MODEL_CARD.md\"), 'w') as f:\n",
    "        f.write(model_card)\n",
    "\n",
    "    # Create zip archive\n",
    "    archive_path = shutil.make_archive(\n",
    "        os.path.join(export_dir, \"constraint-reasoner-v1\"),\n",
    "        'zip',\n",
    "        export_model_path\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"✓ MODEL EXPORT COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Model directory: {export_model_path}\")\n",
    "    print(f\"Archive: {archive_path}\")\n",
    "    print()\n",
    "    print(\"Next steps:\")\n",
    "    print(\"  1. Upload to Kaggle Models: https://www.kaggle.com/models\")\n",
    "    print(\"  2. (Optional) Run 03_train_grpo.ipynb for RL optimization\")\n",
    "    print()\n",
    "\n",
    "else:\n",
    "    print(\"⚠️  Model directory not found, skipping export\")\n",
    "    print(f\"Expected path: {model_path}\")\n",
    "    print(\"Make sure to run 01_train_sft.ipynb first\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
