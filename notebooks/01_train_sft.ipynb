{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 1: Baseline SFT Training\n",
                "\n",
                "Trains `google/gemma-2b` on the constraint optimization dataset using Tunix (JAX/Flax)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import jax\n",
                "import jax.numpy as jnp\n",
                "from typing import Dict, List\n",
                "\n",
                "sys.path.append(os.path.abspath(\"../src\"))\n",
                "\n",
                "from data_loader import OptimizationDataset, DatasetEntry\n",
                "from format_utils import format_input\n",
                "\n",
                "import tunix\n",
                "from tunix.config import TrainerConfig, ModelConfig, OptimizerConfig\n",
                "from tunix.trainer import SFTTrainer\n",
                "from tunix.data import Dataset as TunixDataset\n",
                "\n",
                "print(f\"JAX Devices: {jax.devices()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = OptimizationDataset(size=500)\n",
                "print(f\"Loaded {len(dataset)} examples.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prepare_data(data_loader: OptimizationDataset) -> List[Dict[str, str]]:\n",
                "    prepared = []\n",
                "    for entry in data_loader:\n",
                "        prepared.append({\n",
                "            \"prompt\": format_input(entry['problem']),\n",
                "            \"response\": entry['target']\n",
                "        })\n",
                "    return prepared\n",
                "\n",
                "raw_data = prepare_data(dataset)\n",
                "train_ds = TunixDataset.from_list(raw_data)\n",
                "print(f\"Prepared Tunix Dataset with {len(train_ds)} items.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_config = ModelConfig(\n",
                "    base_model=\"google/gemma-2b\",\n",
                "    dtype=\"bfloat16\",\n",
                "    use_flash_attention=True,\n",
                "    lora_rank=8,\n",
                "    lora_alpha=32,\n",
                "    lora_dropout=0.1\n",
                ")\n",
                "\n",
                "optimizer_config = OptimizerConfig(\n",
                "    learning_rate=2e-5,\n",
                "    scheduler_type=\"cosine\",\n",
                "    warmup_steps=100,\n",
                "    weight_decay=0.01\n",
                ")\n",
                "\n",
                "trainer_config = TrainerConfig(\n",
                "    output_dir=\"../checkpoints/sft_baseline\",\n",
                "    num_epochs=3,\n",
                "    per_device_train_batch_size=4,\n",
                "    gradient_accumulation_steps=4,\n",
                "    max_seq_length=1024,\n",
                "    logging_steps=10,\n",
                "    save_steps=100,\n",
                "    eval_steps=50,\n",
                "    save_total_limit=2,\n",
                "    seed=42\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer = SFTTrainer(\n",
                "    model_config=model_config,\n",
                "    trainer_config=trainer_config,\n",
                "    optimizer_config=optimizer_config,\n",
                "    train_dataset=train_ds,\n",
                ")\n",
                "\n",
                "trainer.train()\n",
                "\n",
                "trainer.save_model(\"../models/constraint-reasoner-v1\")\n",
                "print(\"Training complete and model saved.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}