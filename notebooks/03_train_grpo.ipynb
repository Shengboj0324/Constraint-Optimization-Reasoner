{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 3: Advanced Optimization with GRPO\n",
                "\n",
                "Uses Group Relative Policy Optimization (RL) to refine the model. \n",
                "We use the **Verifiers** as reward functions to encourage:\n",
                "1. Correct Format\n",
                "2. Feasibility (Constraint Satisfaction)\n",
                "3. Optimality (Finding the best solution)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import jax\n",
                "\n",
                "sys.path.append(os.path.abspath(\"../src\"))\n",
                "\n",
                "from data_loader import OptimizationDataset\n",
                "from format_utils import format_input\n",
                "from rewards import format_reward_func, feasibility_reward_func, optimality_reward_func\n",
                "\n",
                "import tunix\n",
                "from tunix.rl import GRPOTrainer, RLConfig\n",
                "from tunix.config import ModelConfig\n",
                "\n",
                "print(f\"JAX Devices: {jax.devices()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Load Data (Prompts only for RL)\n",
                "dataset = OptimizationDataset(size=500)\n",
                "prompts = [format_input(item['problem']) for item in dataset]\n",
                "print(f\"Loaded {len(prompts)} prompts for RL.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Configure Rewards\n",
                "# Tunix RL expects a list of reward functions\n",
                "reward_funcs = [\n",
                "    format_reward_func,      # Basic gate\n",
                "    feasibility_reward_func, # Constraint check\n",
                "    optimality_reward_func   # Optimality check\n",
                "]\n",
                "\n",
                "# 3. Configure RL Training\n",
                "rl_config = RLConfig(\n",
                "    output_dir=\"../checkpoints/grpo_optimized\",\n",
                "    num_train_epochs=1,\n",
                "    per_device_train_batch_size=4,\n",
                "    gradient_accumulation_steps=4,\n",
                "    learning_rate=1e-6, # Lower LR for RL fine-tuning\n",
                "    kl_coeff=0.01,       # Stay close to SFT model\n",
                "    num_generations=4,   # Generate 4 completions per prompt to compare group\n",
                "    max_prompt_length=256,\n",
                "    max_completion_length=1024,\n",
                ")\n",
                "\n",
                "model_config = ModelConfig(\n",
                "    base_model=\"../models/constraint-reasoner-v1\", # Start from SFT checkpoint\n",
                "    dtype=\"bfloat16\",\n",
                "    use_flash_attention=True,\n",
                "    lora_rank=8,\n",
                "    lora_alpha=32\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Train\n",
                "trainer = GRPOTrainer(\n",
                "    model_config=model_config,\n",
                "    rl_config=rl_config,\n",
                "    reward_funcs=reward_funcs,\n",
                "    train_dataset=prompts\n",
                ")\n",
                "\n",
                "trainer.train()\n",
                "trainer.save_model(\"../models/constraint-reasoner-v2-rl\")\n",
                "print(\"GRPO Training complete.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}